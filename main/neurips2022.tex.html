
<!DOCTYPE html>
<meta charset="utf-8">
<html>
  <head>
    <title>A stochastic review of NeurIPS 2022</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    <script src="https://fpcdn.s3.amazonaws.com/apps/polygon-tools/0.4.6/polygon-tools.min.js" type="text/javascript"></script>
    
    <link rel="stylesheet" href="main.css">
    <meta name="viewport" content="width=device-width, initial-scale=1">
  </head>
  <body>
   <div class="content">
   <center><a href="http://folinoid.com/">[Home]</a></center><br/><br/>
     




Welcome to my hastily written overview of NeurIPS 2022. I made this public, but use it with discretion, some of the summaries may be from me glancing at the abstract for 17.4 seconds.<br/>

<ul class="toc"><li>1 <a href="#s1">Biology & Friends</a></li>
<li>2 <a href="#s2">Reinforcement Learning</a></li>
<li>3 <a href="#s3">Deep Learning</a></li>
<li>3.1 <a href="#s4">Deep Learning Theory</a></li>
<li>3.2 <a href="#s5">Graph Neural Networks</a></li></ul>

<a name="s1"></a><h3>1 Biology & Friends</h3>

<a class="tooltip" href="https://openreview.net/forum?id=vRrFVHxFiXJ"><span>Leon Hetzel, Simon Boehm, Niki Kilbertus, Stephan Günnemann, Mohammad Lotfollahi, Fabian J Theis<br/><i>Predicting Cellular Responses to Novel Drug Perturbations at a Single-Cell Resolution</i>, 2022</span>Leon Hetzel et al. (2022)</a> introduce chemCPA, which learns representations of pheno/expression data in a disentangled way. Some gene expression <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal">x</span></span></span></span> is encoded into <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span>, and is made adversarially to not contain any information about the perturbation (genetic or drug), which yields the basal state. Then the drug and cell line information are added back in via graph encoder + cell embedding, sent to be reconstructed by a decoder. This induces a model that can make predictions about, e.g. drugs not in the dataset.
<a name="s2"></a><h3>2 Reinforcement Learning</h3>

Perhaps one of my favorite papers this year is <a class="tooltip" href="https://openreview.net/forum?id=qTCiw1frE_l"><span>Tom Schaul, Andre Barreto, John Quan, Georg Ostrovski<br/><i>The Phenomenon of Policy Churn</i>, 2022</span>Tom Schaul et al. (2022)</a><sup><a href="https://neurips.cc/virtual/2022/poster/54098">[poster]</a></sup>'s Policy Churn results, showing that the greedy policy in deep value-based methods changes significantly (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∼</mo></mrow><annotation encoding="application/x-tex">\sim</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">∼</span></span></span></span>10% of actions) <i>after every gradient step</i>. This is true in DQN, DDQN, R2D2. It is a significant driver of exploration, is consistent across environments, stays high late in training, is not due to redundant actions, and gets worse with network depth.<br/>
<br/>
Some ``Unsupervised RL'' contributions; <a class="tooltip" href="https://openreview.net/forum?id=NL05_JGVg99"><span>Robert Meier, Asier Mujika<br/><i>Open-Ended Reinforcement Learning with Neural Reward Functions</i>, 2022</span>Robert Meier et al. (2022)</a> suggest iteratively learning skills in some kind of contrastive way, where positive samples for a new skill's reward are states the agent can reach, negatives samples being those it can't reach.<br/>
In theory land, <a class="tooltip" href="https://openreview.net/forum?id=vK53GLZJes8"><span>Gaurav Manek, J Zico Kolter<br/><i>The Pitfalls of Regularization in Off-Policy {TD} Learning</i>, 2022</span>Gaurav Manek et al. (2022)</a> show that regularization+offpolicy+TD can have unexpected non-monotonic effects. <a class="tooltip" href="https://openreview.net/forum?id=fORXbIlTELP"><span>Dilip Arumugam, Benjamin Van Roy<br/><i>Deciding What to Model: Value-Equivalent Sampling for Reinforcement Learning</i>, 2022</span>Dilip Arumugam et al. (2022)</a> show some interesting relationships between model compression and planning from a rate-distortion theory perspective.<br/>

<a name="s3"></a><h3>3 Deep Learning</h3>

Maybe relevant to our too-large-datasets problems is <a class="tooltip" href="https://openreview.net/forum?id=2clwrA2tfik"><span>Yongchao Zhou, Ehsan Nezhadarya, Jimmy Ba<br/><i>Dataset Distillation using Neural Feature Regression</i>, 2022</span>Yongchao Zhou et al. (2022)</a><sup><a href="https://neurips.cc/virtual/2022/poster/53822">[poster]</a></sup>'s dataset distillation method based on meta-learning a small set of training inputs on which a model trains well (this is done through the last layer, the rest is frozen during meta-learning). There are at least two more distillation papers at NeurIPS, didn't check them out.<br/>
<a name="s4"></a><h4>3.1 Deep Learning Theory</h4>

Interesting results from Andrew Saxe's group on linear DNNs; <a class="tooltip" href="https://openreview.net/forum?id=lJx2vng-KiC"><span>Lukas Braun, Clémentine Carla Juliette Dominé, James E Fitzgerald, Andrew M Saxe<br/><i>Exact learning dynamics of deep linear networks with prior knowledge</i>, 2022</span>Lukas Braun et al. (2022)</a><sup><a href="https://neurips.cc/virtual/2022/poster/52896">[poster]</a></sup> show how classes of initialization exactly impact learning dynamics, with some interesting consequences for continual learning that cleanly depend on task similarity. <a class="tooltip" href="https://openreview.net/forum?id=XDZhagjfMP"><span>Gal Vardi, Gilad Yehudai, Ohad Shamir<br/><i>Gradient Methods Provably Converge to Non-Robust Networks</i>, 2022</span>Gal Vardi et al. (2022)</a> prove that gradient flows converge to non-robust (adversarially) ReLU networks, even if they are max-margin solutions there exists a universal perturbation that flips the label. <a class="tooltip" href="https://openreview.net/forum?id=AlpR6dzKjfy"><span>Diane Oyen, Michal Kucer, Nick Hengartner, Har Simrat Singh<br/><i>Robustness to Label Noise Depends on the Shape of the Noise Distribution</i>, 2022</span>Diane Oyen et al. (2022)</a> link the dependency of label noise to feature or class information with different tipping points (after which there is ``too much noise''); theory matches our intuition that correlated noise is worse than random noise.<br/>
<a name="s5"></a><h4>3.2 Graph Neural Networks</h4>

<a class="tooltip" href="https://openreview.net/forum?id=AyGJDpN2eR6"><span>Anders Aamand, Justin Y Chen, Piotr Indyk, Shyam Narayanan, Ronitt Rubinfeld, Nicholas Schiefer, Sandeep Silwal, Tal Wagner<br/><i>Exponentially Improving the Complexity of Simulating the Weisfeiler-Lehman Test with Graph Neural Networks</i>, 2022</span>Anders Aamand et al. (2022)</a> derive a stochastic version of a WL-passing GNN with logarithmic numbers of bits.<br/>
<a class="tooltip" href="https://openreview.net/forum?id=seYcx6CqPe"><span>Cédric Vincent-Cuaz, Rémi Flamary, Marco Corneli, Titouan Vayer, Nicolas Courty<br/><i>Template based Graph Neural Network with Optimal Transport Distances</i>, 2022</span>Cédric Vincent-Cuaz et al. (2022)</a><sup><a href="https://neurips.cc/virtual/2022/poster/53079">[poster]</a></sup> propose a new pooling layer based on (a) learned graph templates (b) features that are based on optimal-transport distance to those templates. Funky but I can't say I really understand it.

   </div>
   <div style='height: 10em;'></div>
  </body>
</html>
